# --- 1. –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ ---
import os
import logging
import base64
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
import tempfile

from docx import Document as WordDocument
from openpyxl import Workbook as ExcelWorkbook
from fpdf import FPDF

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from langchain.prompts import ChatPromptTemplate
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain.memory import ConversationBufferWindowMemory
from langchain_tavily import TavilySearch
from langchain.chains import RetrievalQA
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter

# --- 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
load_dotenv()
if "GOOGLE_API_KEY" not in os.environ or "TELEGRAM_BOT_TOKEN" not in os.environ or "TAVILY_API_KEY" not in os.environ:
    raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–ª—é—á–∏ API –≤ .env —Ñ–∞–π–ª–µ!")
print("‚úÖ –ö–ª—é—á–∏ API –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")

# --- 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–ò-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ ---
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0.7)
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
print("‚úÖ LLM –∏ –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")

# --- 4. –ï–î–ò–ù–ê–Ø –ë–ê–ó–ê –ó–ù–ê–ù–ò–ô –ò –§–£–ù–ö–¶–ò–ò-–ò–ù–°–¢–†–£–ú–ï–ù–¢–´ ---
print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")
# –°–æ–∑–¥–∞–µ–º –û–î–ò–ù –æ–±—ä–µ–∫—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤—Å–µ–º–∏
persistent_storage_path = "/var/data/main_chroma_db"
main_db = Chroma(persist_directory=persistent_storage_path, embedding_function=embeddings)
print(f"‚úÖ –ï–¥–∏–Ω–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –≥–æ—Ç–æ–≤–∞. –ó–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ: {main_db._collection.count()}")

def create_word_document(content: str) -> str:
    doc = WordDocument()
    if content.startswith("# "):
        title, _, text = content.partition('\n')
        doc.add_heading(title[2:], level=1)
        doc.add_paragraph(text)
    else:
        doc.add_paragraph(content)
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".docx", prefix="report_")
    doc.save(temp_file.name)
    return temp_file.name

def create_excel_document(content: str) -> str:
    wb = ExcelWorkbook()
    ws = wb.active
    for line in content.split('\n'):
        ws.append(line.split(','))
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx", prefix="table_")
    wb.save(temp_file.name)
    return temp_file.name

def create_pdf_document(content: str) -> str:
    pdf = FPDF()
    pdf.add_page()
    pdf.add_font('DejaVu', '', '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', uni=True)
    pdf.set_font('DejaVu', '', 12)
    pdf.multi_cell(0, 10, content)
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf", prefix="document_")
    pdf.output(temp_file.name)
    return temp_file.name

# –£–õ–£–ß–®–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –°–ê–ú–û–û–ë–£–ß–ï–ù–ò–Ø
def research_and_learn(topic: str) -> str:
    """–ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Å–æ–∑–¥–∞–µ—Ç —Å–∞–º–º–∞—Ä–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –µ–≥–æ –≤ –µ–¥–∏–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π."""
    logger.info(f"–ù–∞—á–∏–Ω–∞—é –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ —Ç–µ–º–µ: {topic}")
    search = TavilySearch(max_results=3)
    search_results = search.invoke(topic)

    if not search_results:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ."

    raw_text = ""
    for result in search_results:
        raw_text += result + "\n\n"

    summarizer_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –ø–æ —Ç–µ–º–µ '{topic}'.
    –°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏, –≤—ã–¥–µ–ª–∏–≤ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã.
    –û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–º —Å–∞–º–º–∞—Ä–∏.
    –¢–ï–ö–°–¢: {raw_text}"""
    
    summary = llm.invoke(summarizer_prompt).content
    logger.info("–°–æ–∑–¥–∞–Ω–æ —Å–∞–º–º–∞—Ä–∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.")

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    texts = text_splitter.create_documents([summary], metadatas=[{"source": f"Research on {topic}"}])
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –ï–î–ò–ù–£–Æ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    main_db.add_documents(texts)
    logger.info(f"–°–∞–º–º–∞—Ä–∏ –ø–æ —Ç–µ–º–µ '{topic}' —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –µ–¥–∏–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π.")
    return f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ '{topic}' –±—ã–ª–∞ —É—Å–ø–µ—à–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –º–æ–µ–π –ø–∞–º—è—Ç–∏."

# --- 5. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ ---
# –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É –¥–ª—è –ê—Ä—Ö–∏–≤–∞—Ä–∏—É—Å–∞, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ï–î–ò–ù–û–ô –±–∞–∑–æ–π
archivist_chain = RetrievalQA.from_chain_type(llm, retriever=main_db.as_retriever())

tools = [
    Tool(
        name="Researcher",
        func=research_and_learn,
        description="–ò—Å–ø–æ–ª—å–∑—É–π, —á—Ç–æ–±—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –Ω–æ–≤—É—é —Ç–µ–º—É –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –µ–µ –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—É—é –ø–∞–º—è—Ç—å."
    ),
    Tool(
        name="Archivist",
        func=archivist_chain.invoke,
        description="–ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –£–ñ–ï –ï–°–¢–¨ –≤ –ø–∞–º—è—Ç–∏."
    ),
    Tool(name="CreateWordDocument", func=create_word_document, description="–ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ Word (.docx)."),
    Tool(name="CreateExcelDocument", func=create_excel_document, description="–ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ Excel (.xlsx)."),
    Tool(name="CreatePdfDocument", func=create_pdf_document, description="–ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è PDF –¥–æ–∫—É–º–µ–Ω—Ç–∞ (.pdf).")
]
print(f"‚úÖ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã: {[tool.name for tool in tools]}")

# --- 6. –°–æ–∑–¥–∞–Ω–∏–µ –ì–ª–∞–≤–Ω–æ–≥–æ –ê–≥–µ–Ω—Ç–∞ —Å –ü–∞–º—è—Ç—å—é ---
memory = ConversationBufferWindowMemory(k=4, memory_key="chat_history", input_key="input")
agent_prompt_template = """–¢—ã ‚Äî –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢–≤–æ—è –≥–ª–∞–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã–ø–æ–ª–Ω—è—Ç—å —Ü–µ–ª–∏, –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.
–¢—ã –¥–æ–ª–∂–µ–Ω —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ.

–ò–°–¢–û–†–ò–Ø –î–ò–ê–õ–û–ì–ê:
{chat_history}

–î–û–°–¢–£–ü–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´:
{tools}

–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1.  **–ü—Ä–æ–≤–µ—Ä–∫–∞ –ü–∞–º—è—Ç–∏:** –ü—Ä–µ–∂–¥–µ —á–µ–º –∏—Å–∫–∞—Ç—å –Ω–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é ('Researcher'), –≤—Å–µ–≥–¥–∞ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—å, –Ω–µ—Ç –ª–∏ –æ—Ç–≤–µ—Ç–∞ –≤ –ø–∞–º—è—Ç–∏ ('Archivist').
2.  **–û—Ç—á–µ—Ç –æ–± –û—à–∏–±–∫–µ:** –ï—Å–ª–∏ 'Archivist' –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Ç–≤–æ–π 'Final Answer' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å: "–í –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–∞–π—Ç–µ –∫–æ–º–∞–Ω–¥—É –Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ."
3.  **–°–æ–∑–¥–∞–Ω–∏–µ –§–∞–π–ª–æ–≤:** –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¢–û–õ–¨–ö–û –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ø–í–ù–û –ø–æ–ø—Ä–æ—Å–∏–ª –æ–± —ç—Ç–æ–º.
4.  **–í—ã–≤–æ–¥ –§–∞–π–ª–∞:** –ï—Å–ª–∏ —Ç—ã —Å–æ–∑–¥–∞–µ—à—å –¥–æ–∫—É–º–µ–Ω—Ç, —Ç–≤–æ–π 'Final Answer' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¢–û–õ–¨–ö–û –ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É.

–ò–°–ü–û–õ–¨–ó–£–ô –°–õ–ï–î–£–Æ–©–ò–ô –§–û–†–ú–ê–¢:
Question: –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
Thought: –ú–æ–∏ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –∏ –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π.
Action: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ [{tool_names}]
Action Input: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞.
Observation: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞.
Thought: –Ø –¥–æ—Å—Ç–∏–≥ —Ü–µ–ª–∏.
Final Answer: –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.

–ù–∞—á–∏–Ω–∞–µ–º!

Question: {input}
Thought:{agent_scratchpad}"""
agent_prompt = ChatPromptTemplate.from_template(agent_prompt_template)
agent = create_react_agent(llm, tools, agent_prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True, handle_parsing_errors=True)
print("‚úÖ –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –ê–≥–µ–Ω—Ç c –µ–¥–∏–Ω–æ–π –ø–∞–º—è—Ç—å—é —Å–æ–∑–¥–∞–Ω.")

# --- 7. –§—É–Ω–∫—Ü–∏–∏-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è Telegram ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text('–ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ü–æ—Å—Ç–∞–≤—å—Ç–µ –º–Ω–µ –∑–∞–¥–∞—á—É –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.')

async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_query = update.message.text
    logger.info(f"–ü–æ–ª—É—á–µ–Ω–∞ –∑–∞–¥–∞—á–∞: '{user_query}'")
    await update.message.reply_text('–ü—Ä–∏—Å—Ç—É–ø–∞—é –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –∑–∞–¥–∞—á–∏...')
    try:
        result = agent_executor.invoke({"input": user_query})
        response_text = result["output"]
        if os.path.exists(response_text) and response_text.endswith(('.docx', '.xlsx', '.pdf')):
            try:
                await context.bot.send_document(chat_id=update.effective_chat.id, document=open(response_text, 'rb'))
                os.remove(response_text)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}", exc_info=True)
                await update.message.reply_text(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç.")
        else:
            await update.message.reply_text(response_text)
            logger.info("–û—Ç–ø—Ä–∞–≤–ª–µ–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç.")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞: {e}", exc_info=True)
        await update.message.reply_text(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞.")

async def handle_photo_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    logger.info("–ü–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
    await update.message.reply_text('–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...')
    try:
        photo_file = await update.message.photo[-1].get_file()
        photo_bytes = await photo_file.download_as_bytearray()
        user_caption = update.message.caption or "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ."
        base64_image = base64.b64encode(photo_bytes).decode("utf-8")
        message_payload = HumanMessage(content=[{"type": "text", "text": user_caption}, {"type": "image_url", "image_url": f"data:image/jpeg;base64,{base64_image}"},])
        response = llm.invoke([message_payload])
        await update.message.reply_text(response.content)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}", exc_info=True)
        await update.message.reply_text(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")

# --- 8. –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞ ---
def main() -> None:
    application = Application.builder().token(os.environ["TELEGRAM_BOT_TOKEN"]).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_message))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo_message))
    print("üöÄ –ó–∞–ø—É—Å–∫–∞—é –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ Telegram-–±–æ—Ç–∞...")
    application.run_polling()

if __name__ == '__main__':
    main()